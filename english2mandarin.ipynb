{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08c9da2-af1d-40ce-9c25-21bef5ae9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timeit import default_timer as timer\n",
    "from torch.nn import Transformer\n",
    "from torch import Tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b7140-68aa-405f-b206-822c7cfff519",
   "metadata": {},
   "source": [
    "## Create Token Dict for SRC and TGT Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcc95e-a7f2-49be-9e5e-e6966659326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the required package\n",
    "# !python3 -m spacy download en_core_web_sm\n",
    "# !python3 -m spacy download zh_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "258808de-0dd5-45fb-aff2-e63a9e7efa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'zh'\n",
    "\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='zh_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355d28c-c82b-40a0-ae2a-dfc068936e28",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "647db205-4575-4a0a-8cbd-1007a3f1ad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
      "    service.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 114, in login\n",
      "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 190, in interpreter_login\n",
      "    token = getpass(\"Enter your token (input will not be visible): \")\n",
      "  File \"/usr/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "  File \"/usr/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# download datasets from HuggingFace\n",
    "# !pip install datasets\n",
    "\n",
    "# add tokens from HuggingFace (https://huggingface.co/settings/tokens)\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32dae85d-ca42-4173-bb99-20a1486f1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             English  \\\n",
      "0  For greater sharpness, but with a slight incre...   \n",
      "1  He calls the Green Book, his book of teachings...   \n",
      "2  And the light breeze moves me to caress her lo...   \n",
      "3  They have the blood of martyrs is the White to...   \n",
      "4  Finally, the Lakers head to the Motor City to ...   \n",
      "\n",
      "                                  Mandarin  \n",
      "0   为了更好的锐度，但是附带的会多一些颗粒度，可以使用这个显影剂的1：1稀释液。  \n",
      "1               他还把宣扬自己思想的所谓《绿皮书》称作“新福音书”。  \n",
      "2                            微风推着我去爱抚它的长耳朵  \n",
      "3                           它们的先烈们的鲜血是白流了…  \n",
      "4  最后，在1月31日，湖人将前往汽车城底特律挑战活塞队，活塞近来在东部排名第二。  \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load datasets with the format \"user_name/dataset_name\"\n",
    "dataset = load_dataset(\"SouthernCrossAI/English_to_Mandarin\")\n",
    "\n",
    "# only use CSV_RATIO of the total data\n",
    "CSV_RATIO = 0.20\n",
    "csv = pd.DataFrame(dataset['train'])\n",
    "csv = csv[:int(len(csv) * CSV_RATIO)]\n",
    "print(csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "085a5a1c-c235-4741-b088-c674999fe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for the later usage\n",
    "# csv.to_csv('translation2019zh_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff47aa-0e49-4461-92c3-185549bf226d",
   "metadata": {},
   "source": [
    "## Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8921cb2-9951-4208-af2e-f5b9464ed22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 929057\n",
      "test set size: 103229\n"
     ]
    }
   ],
   "source": [
    "# use TEST_SET_RATIO of the total loaded data as the test set\n",
    "TEST_SET_RATIO = 0.1\n",
    "train_csv, test_csv = train_test_split(csv, test_size=TEST_SET_RATIO)\n",
    "print(\"training set size: {}\\ntest set size: {}\".format(train_csv.__len__(), test_csv.__len__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944a611-1493-45ba-bd92-dd432ebd1994",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "747950f7-644c-4b01-a93e-c416bd16650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return(self.csv['English'].iloc[idx], self.csv['Mandarin'].iloc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee98db6-6065-4d00-a14a-718c9e86a2d3",
   "metadata": {},
   "source": [
    "## Initialise Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3a6f6ad-4999-411e-bf57-519b4328a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(train_csv)\n",
    "valid_dataset = TranslationDataset(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26eab40-c600-4316-883a-e8392ab5d03c",
   "metadata": {},
   "source": [
    "## Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4817d4-fbc0-4f5b-ab84-7250b609d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to yield list of tokens.\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices.\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab.\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object.\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(train_dataset, ln),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f47d97-90ab-4be7-9dd6-10a6940647c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# `src` and `tgt` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], # Tokenization\n",
    "                                               vocab_transform[ln], # Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842534c-98eb-465f-9f1d-5c408832a356",
   "metadata": {},
   "source": [
    "## Define Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7830c-046c-496c-96a4-6fac1ddb39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 192\n",
    "NHEAD = 6\n",
    "FFN_HID_DIM = 192\n",
    "BATCH_SIZE = 192\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "DEVICE = 'cuda'\n",
    "NUM_EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b160ad8-30bb-48f4-bb66-cadc94ddd02d",
   "metadata": {},
   "source": [
    "## Create Masks for SRC and TGT Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe171d-65a7-40a5-8469-9270ae54c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "    src_padding_mask = (src == PAD_IDX)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0b2ac-d555-49d1-9303-02c7d27d853b",
   "metadata": {},
   "source": [
    "## Create a Positional Encoding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdb192-f16a-4362-94c8-25ef017b78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        \"\"\"\n",
    "        :param max_len: Input length sequence.\n",
    "        :param d_model: Embedding dimension.\n",
    "        :param dropout: Dropout value (default=0.1)\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Inputs of forward function\n",
    "        :param x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90dbf8-4318-4d6f-918b-67395323cefd",
   "metadata": {},
   "source": [
    "## Create an Embedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d7ac3-b925-41b5-8d5d-2f225a0a4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277412bc-c4bb-4d9d-adab-7581f003a8c0",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fbb72-4515-4ba4-ac5d-1bef8de56ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        emb_size: int,\n",
    "        nhead: int,\n",
    "        src_vocab_size: int,\n",
    "        tgt_vocab_size: int,\n",
    "        dim_feedforward: int = 512,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cb5a6-9700-4697-abae-48892be4bb7b",
   "metadata": {},
   "source": [
    "## Show the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5193dc-f412-408b-aea1-13bd8e52ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqTransformer(\n",
    "    NUM_ENCODER_LAYERS,\n",
    "    NUM_DECODER_LAYERS,\n",
    "    EMB_SIZE,\n",
    "    NHEAD,\n",
    "    SRC_VOCAB_SIZE,\n",
    "    TGT_VOCAB_SIZE,\n",
    "    FFN_HID_DIM\n",
    ").to(DEVICE)\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5cce8-23ca-4e0f-af57-06d80e66afc9",
   "metadata": {},
   "source": [
    "## Define the Loss Function and Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7864d5-cffb-4d38-9c67-435e96ee5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d26ec-d10c-4eca-8b1e-fbb768a6fca5",
   "metadata": {},
   "source": [
    "## Define DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9f6d8-9f17-4f72-8f5e-04b231f51d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f02c8-88ea-4fba-8c23-05584b0a9cfa",
   "metadata": {},
   "source": [
    "## Define the Training Loop and Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d9719-b6ff-428c-925e-c91dcd08b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for src, tgt in tqdm(train_dataloader, total=len(list(train_dataloader))):\n",
    "        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(\n",
    "            src,\n",
    "            tgt_input,\n",
    "            src_mask,\n",
    "            tgt_mask,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            src_padding_mask\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(list(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e68126-9753-4bd9-bfcb-13c0087258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    print('Validating')\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for src, tgt in tqdm(val_dataloader, total=len(list(val_dataloader))):\n",
    "        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(\n",
    "            src,\n",
    "            tgt_input,\n",
    "            src_mask,\n",
    "            tgt_mask,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            src_padding_mask\n",
    "        )\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5eb5bd-14bb-4fb0-8afa-62638de13af6",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985e486-3988-4a7c-bc0a-987eeda3c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list = [], []\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer)\n",
    "    valid_loss = evaluate(model)\n",
    "    end_time = timer()\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {valid_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s \\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37a3bd-6a6d-4cd5-9216-a1217046076c",
   "metadata": {},
   "source": [
    "## Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a9231-2c65-4260-9771-2e01f8755582",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a715d74-cfad-4239-929a-1617c7f68e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'outputs/model_ratio020_epoch40.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b16b48-834b-4c9a-ab55-4b93b07c31c9",
   "metadata": {},
   "source": [
    "## Save the Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d2f85-4783-4aae-810a-bf9a816fe422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss plots to disk.\n",
    "    \"\"\"\n",
    "    # Loss plots.\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='blue', linestyle='-',\n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-',\n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xticks(range(len(train_loss)))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join('outputs', 'loss.png'))\n",
    "    plt.show()\n",
    "\n",
    "save_plots(train_loss_list, valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e00b4-3672-4e72-bb40-07b29b09111f",
   "metadata": {},
   "source": [
    "## Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4e337-0618-47f9-ae6d-f98f36137491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('outputs/model_ratio020_epoch40.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9060fb-8e9b-4468-b52e-e9cbe925bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate output sequence using greedy algorithm.\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        if i == 0:\n",
    "            ys = ys.transpose(1, 0)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "# Translation function.\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(1, -1)\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46be529-5fdf-4ec0-908d-7d5fc7eaa772",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SRC, GT pairs from the validation set\n",
    "infer_sentences = [\n",
    "    [\"Slowly and not without struggle, America began to listen.\", \"美国缓慢地开始倾听，但并非没有艰难曲折。\"],\n",
    "    [\"Dithering is a technique that blends your colors together, making them look smoother, or just creating interesting textures.\", \"抖动是关于颜色混合的技术，使你的作品看起来更圆滑，或者只是创作有趣的材质。\"],\n",
    "    [\"The second encounter relates to my grandfather's treasure box.\", \"第二次事件跟我爷爷的宝贝匣子有关。\"]\n",
    "]\n",
    "\n",
    "for sentence in infer_sentences:\n",
    "    print(f\"SRC: {sentence[0]}\")\n",
    "    print(f\"GT: {sentence[1]}\")\n",
    "    print(f\"PRED: {translate(model, sentence[0])}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
